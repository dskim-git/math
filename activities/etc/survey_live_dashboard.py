# activities/etc/survey_live_dashboard.py
import time
import pandas as pd
import streamlit as st
import streamlit.components.v1 as components

from survey_utils import (
    make_csv_export_url,
    load_csv_live,
    parse_mcq_series,
    basic_tokenize_korean,
    top_n_tokens,
)

META = {
    "title": "ì‹¤ì‹œê°„ ì„¤ë¬¸ ëŒ€ì‹œë³´ë“œ",
    "description": "êµ¬ê¸€ì‹œíŠ¸ CSVë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì½ì–´ ê·¸ë˜í”„/ì›Œë“œí´ë¼ìš°ë“œë¥¼ ë§Œë“­ë‹ˆë‹¤.",
    "order": 10,
    # "hidden": True,
}

# ì›Œë“œí´ë¼ìš°ë“œ(ì„ íƒ)
WC_AVAILABLE = True
try:
    import matplotlib.pyplot as plt
    from wordcloud import WordCloud
except Exception:
    WC_AVAILABLE = False


def _auto_refresh(seconds: int, key: str = "auto_refresh_survey"):
    """ìµœì‹  ìŠ¤íŠ¸ë¦¼ë¦¿ì€ st.autorefresh, êµ¬ë²„ì „ì€ meta refreshë¡œ í´ë°±."""
    if seconds <= 0:
        return
    try:
        st.autorefresh(interval=seconds * 1000, key=key)  # type: ignore[attr-defined]
    except Exception:
        components.html(f"<meta http-equiv='refresh' content='{int(seconds)}'>", height=0)


def render():
    st.header("ğŸ—³ï¸ ì‹¤ì‹œê°„ ì„¤ë¬¸ ëŒ€ì‹œë³´ë“œ")

    with st.sidebar:
        st.subheader("âš™ï¸ ë°ì´í„° ì†ŒìŠ¤")
        csv_or_sheet_url = st.text_input(
            "ì‹œíŠ¸ URL ë˜ëŠ” CSV ë‚´ë³´ë‚´ê¸° URL",
            placeholder=(
                "ì˜ˆ) https://docs.google.com/spreadsheets/d/FILE_ID/edit#gid=0 "
                "ë˜ëŠ” https://docs.google.com/spreadsheets/d/FILE_ID/export?format=csv&gid=0"
            ),
            help=(
                "â‘  ì‹œíŠ¸ë¥¼ ì—´ê³  ì£¼ì†Œí‘œì‹œì¤„ì˜ ë§í¬ ê·¸ëŒ€ë¡œ ë¶™ì—¬ë„ ë©ë‹ˆë‹¤.\n"
                "   (ì•±ì´ ìë™ìœ¼ë¡œ CSV ë‚´ë³´ë‚´ê¸° ì£¼ì†Œë¡œ ë³€í™˜)\n"
                "â‘¡ ë§Œì•½ 'ì›¹ì— ê²Œì‹œ' ë§í¬ë¥¼ ì“°ë©´ ë°˜ì˜ì´ ëŠ¦ì„ ìˆ˜ ìˆì–´ìš”. "
                "ê°€ëŠ¥í•˜ë©´ export?format=csv&gid=... í˜•íƒœê°€ ê°€ì¥ ë¹ ë¦…ë‹ˆë‹¤."
            ),
        )

        st.caption("ğŸ”— ë³€í™˜ëœ CSV ì£¼ì†Œ(ì½ê¸° ì „ìš©)")
        csv_preview = make_csv_export_url(csv_or_sheet_url) if csv_or_sheet_url else ""
        st.text_area("CSV URL", csv_preview, height=60, label_visibility="collapsed")

        st.subheader("ğŸ” ìƒˆë¡œê³ ì¹¨")
        refresh_sec = st.slider("ìë™ ìƒˆë¡œê³ ì¹¨(ì´ˆ)", 0, 60, 10, help="0ì´ë©´ ìë™ ìƒˆë¡œê³ ì¹¨ ì—†ìŒ")
        manual = st.button("ğŸ”„ ì§€ê¸ˆ ìƒˆë¡œê³ ì¹¨")

        show_raw = st.checkbox("ì›ì‹œ ë°ì´í„° ë³´ê¸°", False)

    # ìë™ ìƒˆë¡œê³ ì¹¨
    if csv_or_sheet_url and refresh_sec > 0:
        _auto_refresh(refresh_sec, key="auto_refresh_survey")

    # ìºì‹œ ë¬´ë ¥í™”ìš© 'bust' ê°’ ìƒì„±
    if manual:
        bust = int(time.time())  # ë²„íŠ¼ ëˆ„ë¥¼ ë•Œë§ˆë‹¤ ê°•ì œ ì¬ë‹¤ìš´ë¡œë“œ
    elif refresh_sec > 0:
        bust = int(time.time() // max(refresh_sec, 1))  # nì´ˆ ë‹¨ìœ„ë¡œ ê°’ì´ ë°”ë€œ
    else:
        bust = 0  # ê°™ì€ ì„¸ì…˜ ë™ì•ˆ ìºì‹œ ìœ ì§€

    @st.cache_data(show_spinner=False)
    def _load(url: str, bust_val: int) -> pd.DataFrame:
        return load_csv_live(url, cache_bust=bust_val)

    if not csv_or_sheet_url:
        st.info("ì¢Œì¸¡ì— **ì‹œíŠ¸ URL ë˜ëŠ” CSV URL**ì„ ì…ë ¥í•˜ë©´ ê·¸ë˜í”„ê°€ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.")
        return

    try:
        df = _load(csv_or_sheet_url, bust)
    except Exception as e:
        st.error(f"CSVë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”: {e}")
        return

    if df.empty:
        st.warning("ì‹œíŠ¸ê°€ ë¹„ì–´ìˆê±°ë‚˜ ì ‘ê·¼ì´ ë¶ˆê°€í•©ë‹ˆë‹¤. ì£¼ì†Œ/ê³µê°œ ì„¤ì •ì„ í™•ì¸í•´ ì£¼ì„¸ìš”.")
        return

    st.success(f"í–‰ {len(df):,}ê°œ Â· ì—´ {len(df.columns)}ê°œ ë¡œë“œë¨ Â· {time.strftime('%H:%M:%S')} ê¸°ì¤€")
    if show_raw:
        st.dataframe(df, use_container_width=True)

    cols = df.columns.tolist()

    # â”€â”€ ê°ê´€ì‹/ì²´í¬ë°•ìŠ¤ ë§‰ëŒ€ê·¸ë˜í”„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.subheader("ğŸ“Š ê·¸ë˜í”„")
    with st.expander("ê°ê´€ì‹/ì²´í¬ë°•ìŠ¤ ë¹ˆë„ ë§‰ëŒ€ê·¸ë˜í”„", expanded=True):
        if cols:
            col_mcq = st.selectbox("ì§ˆë¬¸(ê°ê´€ì‹/ì²´í¬ë°•ìŠ¤ ì—´ ì„ íƒ)", options=cols)
            normalize = st.checkbox("ë°±ë¶„ìœ¨(%)ë¡œ ë³´ê¸°", True)
            if col_mcq:
                counts = parse_mcq_series(df[col_mcq])
                if counts:
                    s = pd.Series(counts).sort_values(ascending=False)
                    if normalize:
                        s = (s / s.sum() * 100).round(1)
                    st.bar_chart(s, use_container_width=True)
                    st.caption(f"ì´ ì‘ë‹µ ìˆ˜: {int(s.sum() if not normalize else (s.sum()/100*len(s)))} / ë²”ì£¼ ìˆ˜: {len(s)}")
                else:
                    st.info("ì§‘ê³„í•  ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("í‘œì‹œí•  ì—´ì´ ì—†ìŠµë‹ˆë‹¤.")

    # â”€â”€ ììœ ì‘ë‹µ ì›Œë“œí´ë¼ìš°ë“œ & ìƒìœ„ ë‹¨ì–´ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with st.expander("ì£¼ê´€ì‹(ììœ ì‘ë‹µ) ì›Œë“œí´ë¼ìš°ë“œ & ìƒìœ„ ë‹¨ì–´", expanded=True):
        if cols:
            # ë³´í†µ ì²« ì—´ì´ íƒ€ì„ìŠ¤íƒ¬í”„ì¸ ê²½ìš°ê°€ ë§ì•„ index=1ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ë‘ 
            default_idx = 1 if len(cols) > 1 else 0
            col_text = st.selectbox("ì§ˆë¬¸(ììœ ì‘ë‹µ ì—´ ì„ íƒ)", options=cols, index=default_idx)
            max_words = st.slider("ë‹¨ì–´ ìˆ˜(ì›Œë“œí´ë¼ìš°ë“œ)", 20, 300, 120)
            user_stop = st.text_area("ì œì™¸í•  ë‹¨ì–´(ì‰¼í‘œë¡œ êµ¬ë¶„)", "ì…ë‹ˆë‹¤, ê·¸ë¦¬ê³ , ë˜ëŠ”, ì •ë§")
            stopwords = [w.strip() for w in user_stop.split(",") if w.strip()]

            texts = df[col_text].dropna().astype(str).tolist()
            tokens = basic_tokenize_korean(texts)
            top_tokens = top_n_tokens(tokens, n=50, stopwords=stopwords)

            if top_tokens:
                st.write("ìƒìœ„ ë‹¨ì–´")
                st.dataframe(
                    pd.DataFrame(top_tokens, columns=["ë‹¨ì–´", "ë¹ˆë„"]),
                    use_container_width=True, hide_index=True
                )
            else:
                st.info("í‘œì‹œí•  ë‹¨ì–´ê°€ ì—†ìŠµë‹ˆë‹¤.")

            if WC_AVAILABLE and tokens:
                FONT_PATH = "assets/NanumGothic.ttf"  # í”„ë¡œì íŠ¸ì— í°íŠ¸ íŒŒì¼ì„ ë‘ì„¸ìš”.
                try:
                    wc = WordCloud(
                        width=900, height=500,
                        background_color="white",
                        font_path=FONT_PATH,
                        max_words=max_words,
                    ).generate(" ".join(tokens))
                    fig = plt.figure(figsize=(9, 5))
                    plt.imshow(wc, interpolation="bilinear")
                    plt.axis("off")
                    st.pyplot(fig, use_container_width=True)
                except Exception as e:
                    st.warning(f"ì›Œë“œí´ë¼ìš°ë“œë¥¼ í‘œì‹œí•˜ë ¤ë©´ í•œê¸€ í°íŠ¸(.ttf)ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì˜¤ë¥˜: {e}")
            elif not WC_AVAILABLE:
                st.info("ì›Œë“œí´ë¼ìš°ë“œë¥¼ ì“°ë ¤ë©´ requirements.txtì— `wordcloud`, `matplotlib`ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
        else:
            st.info("í‘œì‹œí•  ì—´ì´ ì—†ìŠµë‹ˆë‹¤.")

    with st.expander("ë¹ ë¥¸ ìš”ì•½", expanded=False):
        st.write(df.describe(include="all").transpose())
