# activities/etc/survey_live_dashboard.py
import streamlit as st
import pandas as pd

from survey_utils import (
    load_published_csv, parse_mcq_series,
    basic_tokenize_korean, top_n_tokens
)

# â”€â”€ ë©”íƒ€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
META = {
    "title": "ì‹¤ì‹œê°„ ì„¤ë¬¸ ëŒ€ì‹œë³´ë“œ",
    "description": "êµ¬ê¸€í¼â†’ì‹œíŠ¸(ì›¹ì— ê²Œì‹œÂ·CSV)ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì½ì–´ ê·¸ë˜í”„/ì›Œë“œí´ë¼ìš°ë“œ í‘œì‹œ",
    "order": 10,
    # "hidden": True,  # miniì— ë„£ê±°ë‚˜ ìˆ¨ê¸°ê³  ì‹¶ìœ¼ë©´ True
}

# â”€â”€ WordCloud ì˜µì…˜(ì„ íƒ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì›Œë“œí´ë¼ìš°ë“œë¥¼ ì“°ë ¤ë©´ wordcloud, matplotlibê°€ í•„ìš”í•©ë‹ˆë‹¤.
# requirements.txtì—: wordcloud, matplotlib ì¶”ê°€
WC_AVAILABLE = True
try:
    import matplotlib.pyplot as plt
    from wordcloud import WordCloud
except Exception:
    WC_AVAILABLE = False


def render():
    st.header("ğŸ—³ï¸ ì‹¤ì‹œê°„ ì„¤ë¬¸ ëŒ€ì‹œë³´ë“œ")

    with st.sidebar:
        st.subheader("âš™ï¸ ì„¤ì •")
        csv_url = st.text_input(
            "êµ¬ê¸€ì‹œíŠ¸(ì›¹ì— ê²Œì‹œÂ·CSV) ì£¼ì†Œ",
            placeholder="https://docs.google.com/spreadsheets/d/e/2PACX-.../pub?gid=0&single=true&output=csv",
            help="ì‹œíŠ¸ > íŒŒì¼ > ì›¹ì— ê²Œì‹œ > (íŠ¹ì • ì‹œíŠ¸ íƒ­, í˜•ì‹: CSV) í›„ ë‚˜ì˜¨ ë§í¬ë¥¼ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”."
        )
        refresh_sec = st.slider("ìë™ ìƒˆë¡œê³ ì¹¨(ì´ˆ)", 5, 60, 10)
        show_raw = st.checkbox("ì›ì‹œ ë°ì´í„° ë³´ê¸°", False)

        # ìë™ ìƒˆë¡œê³ ì¹¨
        st.autorefresh(interval=refresh_sec * 1000, key="auto_refresh_survey")

    # ë°ì´í„° ë¡œë“œ (TTL=refresh_sec-1ë¡œ ìºì‹œ)
    @st.cache_data(ttl=30)
    def _load(url: str) -> pd.DataFrame:
        return load_published_csv(url)

    if not csv_url:
        st.info("ì¢Œì¸¡ì— **CSV ì£¼ì†Œ**ë¥¼ ì…ë ¥í•˜ë©´ ê·¸ë˜í”„ê°€ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.")
        return

    try:
        df = _load(csv_url)
    except Exception as e:
        st.error(f"CSVë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”: {e}")
        return

    if df.empty:
        st.warning("ì‹œíŠ¸ê°€ ë¹„ì–´ìˆê±°ë‚˜ ì ‘ê·¼ì´ ë¶ˆê°€í•©ë‹ˆë‹¤. ì£¼ì†Œ/ê³µê°œ ì„¤ì •ì„ í™•ì¸í•´ ì£¼ì„¸ìš”.")
        return

    st.success(f"í–‰ {len(df):,}ê°œ, ì—´ {len(df.columns)}ê°œ ë¡œë“œë¨")

    if show_raw:
        st.dataframe(df, use_container_width=True)

    # â”€â”€ ì»¬ëŸ¼ ì„ íƒ UI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.subheader("ğŸ“Š ê·¸ë˜í”„")
    cols = df.columns.tolist()

    # 1) ê°ê´€ì‹/ì²´í¬ë°•ìŠ¤ ê·¸ë˜í”„(ë§‰ëŒ€)
    with st.expander("ê°ê´€ì‹/ì²´í¬ë°•ìŠ¤ ë¹ˆë„ ë§‰ëŒ€ê·¸ë˜í”„", expanded=True):
        col_mcq = st.selectbox("ì§ˆë¬¸(ê°ê´€ì‹/ì²´í¬ë°•ìŠ¤ ì—´ ì„ íƒ)", options=cols)
        normalize = st.checkbox("ë°±ë¶„ìœ¨(%)ë¡œ ë³´ê¸°", True)
        if col_mcq:
            counts = parse_mcq_series(df[col_mcq])
            if counts:
                s = pd.Series(counts).sort_values(ascending=False)
                if normalize:
                    s = (s / s.sum() * 100).round(1)
                    st.bar_chart(s, use_container_width=True)
                    st.caption(f"ì´ ì‘ë‹µ ìˆ˜: {int(s.sum() if not normalize else counts.total())} / ë²”ì£¼ ìˆ˜: {len(s)}")
                else:
                    st.bar_chart(s, use_container_width=True)
                    st.caption(f"ì´ ì‘ë‹µ ìˆ˜: {counts.total()} / ë²”ì£¼ ìˆ˜: {len(s)}")
            else:
                st.info("ì§‘ê³„í•  ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤.")

    # 2) ììœ ì‘ë‹µ(ì›Œë“œí´ë¼ìš°ë“œ/ìƒìœ„ í† í°í‘œ)
    with st.expander("ì£¼ê´€ì‹(ììœ ì‘ë‹µ) ì›Œë“œí´ë¼ìš°ë“œ & ìƒìœ„ ë‹¨ì–´", expanded=True):
        col_text = st.selectbox("ì§ˆë¬¸(ììœ ì‘ë‹µ ì—´ ì„ íƒ)", options=cols, index=min(1, len(cols)-1))
        max_words = st.slider("ë‹¨ì–´ ìˆ˜(ì›Œë“œí´ë¼ìš°ë“œ)", 20, 300, 120)
        user_stop = st.text_area("ì œì™¸í•  ë‹¨ì–´(ì‰¼í‘œë¡œ êµ¬ë¶„)", "ì…ë‹ˆë‹¤, ê·¸ë¦¬ê³ , ë˜ëŠ”, í•™ìƒ, ìˆ˜ì—…, ì •ë§")
        stopwords = [w.strip() for w in user_stop.split(",") if w.strip()]

        if col_text:
            texts = df[col_text].dropna().astype(str).tolist()
            tokens = basic_tokenize_korean(texts)
            top_tokens = top_n_tokens(tokens, n=50, stopwords=stopwords)

            # ìƒìœ„ í† í° í…Œì´ë¸”
            if top_tokens:
                st.write("ìƒìœ„ ë‹¨ì–´")
                st.dataframe(
                    pd.DataFrame(top_tokens, columns=["ë‹¨ì–´", "ë¹ˆë„"]),
                    use_container_width=True, hide_index=True
                )
            else:
                st.info("í‘œì‹œí•  ë‹¨ì–´ê°€ ì—†ìŠµë‹ˆë‹¤(ëª¨ë‘ stopwordsë¡œ ì œì™¸ë˜ì—ˆê±°ë‚˜ ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤).")

            # ì›Œë“œí´ë¼ìš°ë“œ
            if WC_AVAILABLE and tokens:
                # í•œê¸€ í°íŠ¸ ê²½ë¡œ ì§€ì • (í”„ë¡œì íŠ¸ì— í°íŠ¸ë¥¼ ë„£ì–´ ì‚¬ìš© ê¶Œì¥)
                # ì˜ˆ: assets/NanumGothic.ttf ë¥¼ ì¶”ê°€í•˜ê³  ì•„ë˜ ê²½ë¡œ ì§€ì •
                FONT_PATH = "assets/NanumGothic.ttf"  # ê²½ë¡œì— ë§ê²Œ ìˆ˜ì •
                try:
                    wc = WordCloud(
                        width=900, height=500,
                        background_color="white",
                        font_path=FONT_PATH,
                        max_words=max_words,
                    ).generate(" ".join(tokens))
                    import matplotlib.pyplot as plt
                    fig = plt.figure(figsize=(9, 5))
                    plt.imshow(wc, interpolation="bilinear")
                    plt.axis("off")
                    st.pyplot(fig, use_container_width=True)
                except Exception as e:
                    st.warning(f"ì›Œë“œí´ë¼ìš°ë“œë¥¼ í‘œì‹œí•˜ë ¤ë©´ í•œê¸€ í°íŠ¸(.ttf)ê°€ í•„ìš”í•©ë‹ˆë‹¤. í˜„ì¬ ì˜¤ë¥˜: {e}")
            elif not WC_AVAILABLE:
                st.info("ì›Œë“œí´ë¼ìš°ë“œë¥¼ ì“°ë ¤ë©´ requirements.txtì— `wordcloud`, `matplotlib`ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")

    # 3) ë¹ ë¥¸ ìš”ì•½(ì„ íƒ)
    with st.expander("ë¹ ë¥¸ ìš”ì•½", expanded=False):
        st.write(df.describe(include="all").transpose())
