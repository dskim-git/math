# activities/etc/survey_live_dashboard.py
import streamlit as st
import streamlit.components.v1 as components
import pandas as pd

from survey_utils import (
    load_published_csv, parse_mcq_series,
    basic_tokenize_korean, top_n_tokens
)

META = {
    "title": "ì‹¤ì‹œê°„ ì„¤ë¬¸ ëŒ€ì‹œë³´ë“œ",
    "description": "êµ¬ê¸€í¼â†’ì‹œíŠ¸(ì›¹ì— ê²Œì‹œÂ·CSV)ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì½ì–´ ê·¸ë˜í”„/ì›Œë“œí´ë¼ìš°ë“œ í‘œì‹œ",
    "order": 10,
    # "hidden": True,
}

# ì›Œë“œí´ë¼ìš°ë“œ(ì„ íƒ)
WC_AVAILABLE = True
try:
    import matplotlib.pyplot as plt
    from wordcloud import WordCloud
except Exception:
    WC_AVAILABLE = False


def _auto_refresh(seconds: int, key: str = "auto_refresh_survey"):
    """
    ìµœì‹  ìŠ¤íŠ¸ë¦¼ë¦¿: st.autorefresh ì‚¬ìš©
    êµ¬ë²„ì „: <meta http-equiv='refresh'> í´ë°±
    """
    if seconds <= 0:
        return
    try:
        # ìµœì‹  ìŠ¤íŠ¸ë¦¼ë¦¿
        _ = getattr(st, "autorefresh")
        st.autorefresh(interval=seconds * 1000, key=key)
    except Exception:
        # êµ¬ë²„ì „ í´ë°±: í˜ì´ì§€ ì „ì²´ ìƒˆë¡œê³ ì¹¨
        components.html(
            f"<meta http-equiv='refresh' content='{int(seconds)}'>",
            height=0
        )


def render():
    st.header("ğŸ—³ï¸ ì‹¤ì‹œê°„ ì„¤ë¬¸ ëŒ€ì‹œë³´ë“œ")

    with st.sidebar:
        st.subheader("âš™ï¸ ì„¤ì •")
        csv_url = st.text_input(
            "êµ¬ê¸€ì‹œíŠ¸(ì›¹ì— ê²Œì‹œÂ·CSV) ì£¼ì†Œ",
            placeholder="https://docs.google.com/spreadsheets/d/e/2PACX-.../pub?gid=0&single=true&output=csv",
            help="ì‹œíŠ¸ > íŒŒì¼ > ì›¹ì— ê²Œì‹œ > (íŠ¹ì • ì‹œíŠ¸ íƒ­, í˜•ì‹: CSV) í›„ ë‚˜ì˜¨ ë§í¬ë¥¼ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”."
        )
        refresh_sec = st.slider("ìë™ ìƒˆë¡œê³ ì¹¨(ì´ˆ)", 0, 60, 10,
                                help="0ìœ¼ë¡œ ë‘ë©´ ìë™ ìƒˆë¡œê³ ì¹¨ ë¹„í™œì„±í™”")
        show_raw = st.checkbox("ì›ì‹œ ë°ì´í„° ë³´ê¸°", False)

    # ìë™ ìƒˆë¡œê³ ì¹¨(ì£¼ì†Œê°€ ìˆì„ ë•Œë§Œ)
    if csv_url and refresh_sec:
        _auto_refresh(refresh_sec, key="auto_refresh_survey")

    @st.cache_data(ttl=30)
    def _load(url: str) -> pd.DataFrame:
        return load_published_csv(url)

    if not csv_url:
        st.info("ì¢Œì¸¡ì— **CSV ì£¼ì†Œ**ë¥¼ ì…ë ¥í•˜ë©´ ê·¸ë˜í”„ê°€ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.")
        return

    try:
        df = _load(csv_url)
    except Exception as e:
        st.error(f"CSVë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”: {e}")
        return

    if df.empty:
        st.warning("ì‹œíŠ¸ê°€ ë¹„ì–´ìˆê±°ë‚˜ ì ‘ê·¼ì´ ë¶ˆê°€í•©ë‹ˆë‹¤. ì£¼ì†Œ/ê³µê°œ ì„¤ì •ì„ í™•ì¸í•´ ì£¼ì„¸ìš”.")
        return

    st.success(f"í–‰ {len(df):,}ê°œ, ì—´ {len(df.columns)}ê°œ ë¡œë“œë¨")
    if show_raw:
        st.dataframe(df, use_container_width=True)

    cols = df.columns.tolist()

    # â”€â”€ ê°ê´€ì‹/ì²´í¬ë°•ìŠ¤ ë§‰ëŒ€ê·¸ë˜í”„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.subheader("ğŸ“Š ê·¸ë˜í”„")
    with st.expander("ê°ê´€ì‹/ì²´í¬ë°•ìŠ¤ ë¹ˆë„ ë§‰ëŒ€ê·¸ë˜í”„", expanded=True):
        if cols:
            col_mcq = st.selectbox("ì§ˆë¬¸(ê°ê´€ì‹/ì²´í¬ë°•ìŠ¤ ì—´ ì„ íƒ)", options=cols)
            normalize = st.checkbox("ë°±ë¶„ìœ¨(%)ë¡œ ë³´ê¸°", True)
            if col_mcq:
                counts = parse_mcq_series(df[col_mcq])
                if counts:
                    s = pd.Series(counts).sort_values(ascending=False)
                    if normalize:
                        s = (s / s.sum() * 100).round(1)
                    st.bar_chart(s, use_container_width=True)
                    st.caption(f"ì´ ì‘ë‹µ ìˆ˜: {sum(counts.values())} / ë²”ì£¼ ìˆ˜: {len(s)}")
                else:
                    st.info("ì§‘ê³„í•  ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("í‘œì‹œí•  ì—´ì´ ì—†ìŠµë‹ˆë‹¤.")

    # â”€â”€ ììœ ì‘ë‹µ ì›Œë“œí´ë¼ìš°ë“œ & ìƒìœ„ ë‹¨ì–´ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with st.expander("ì£¼ê´€ì‹(ììœ ì‘ë‹µ) ì›Œë“œí´ë¼ìš°ë“œ & ìƒìœ„ ë‹¨ì–´", expanded=True):
        if cols:
            col_text = st.selectbox("ì§ˆë¬¸(ììœ ì‘ë‹µ ì—´ ì„ íƒ)", options=cols, index=min(1, len(cols)-1))
            max_words = st.slider("ë‹¨ì–´ ìˆ˜(ì›Œë“œí´ë¼ìš°ë“œ)", 20, 300, 120)
            user_stop = st.text_area("ì œì™¸í•  ë‹¨ì–´(ì‰¼í‘œë¡œ êµ¬ë¶„)", "ì…ë‹ˆë‹¤, ê·¸ë¦¬ê³ , ë˜ëŠ”, ì •ë§")
            stopwords = [w.strip() for w in user_stop.split(",") if w.strip()]

            texts = df[col_text].dropna().astype(str).tolist()
            tokens = basic_tokenize_korean(texts)
            top_tokens = top_n_tokens(tokens, n=50, stopwords=stopwords)

            if top_tokens:
                st.write("ìƒìœ„ ë‹¨ì–´")
                st.dataframe(
                    pd.DataFrame(top_tokens, columns=["ë‹¨ì–´", "ë¹ˆë„"]),
                    use_container_width=True, hide_index=True
                )
            else:
                st.info("í‘œì‹œí•  ë‹¨ì–´ê°€ ì—†ìŠµë‹ˆë‹¤.")

            if WC_AVAILABLE and tokens:
                FONT_PATH = "assets/NanumGothic.ttf"  # í”„ë¡œì íŠ¸ì— í°íŠ¸ íŒŒì¼ì„ ë‘ê³  ê²½ë¡œë¥¼ ë§ì¶”ì„¸ìš”.
                try:
                    wc = WordCloud(
                        width=900, height=500,
                        background_color="white",
                        font_path=FONT_PATH,
                        max_words=max_words,
                    ).generate(" ".join(tokens))
                    fig = plt.figure(figsize=(9, 5))
                    plt.imshow(wc, interpolation="bilinear")
                    plt.axis("off")
                    st.pyplot(fig, use_container_width=True)
                except Exception as e:
                    st.warning(f"ì›Œë“œí´ë¼ìš°ë“œë¥¼ í‘œì‹œí•˜ë ¤ë©´ í•œê¸€ í°íŠ¸(.ttf)ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì˜¤ë¥˜: {e}")
            elif not WC_AVAILABLE:
                st.info("ì›Œë“œí´ë¼ìš°ë“œë¥¼ ì“°ë ¤ë©´ requirements.txtì— `wordcloud`, `matplotlib`ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
        else:
            st.info("í‘œì‹œí•  ì—´ì´ ì—†ìŠµë‹ˆë‹¤.")

    # â”€â”€ ìš”ì•½ í†µê³„(ì˜µì…˜) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with st.expander("ë¹ ë¥¸ ìš”ì•½", expanded=False):
        st.write(df.describe(include="all").transpose())
