# activities/probability/sampling_mean_demo_p5.py
# ëª¨ì§‘ë‹¨(êµ¬ê¸€ì‹œíŠ¸) â†’ í‘œë³¸ ë‹¤ì¤‘ ì¶”ì¶œ â†’ í‘œë³¸í‰ê·  ë¶„í¬ë¥¼ p5.jsë¡œ ì‹œê°í™”

from __future__ import annotations
import re
import json
from typing import List, Tuple
from urllib.parse import urlparse, parse_qs, quote

import numpy as np
import pandas as pd
import streamlit as st
import streamlit.components.v1 as components

META = {
    "title": "ëª¨í‰ê· ê³¼ í‘œë³¸í‰ê· ì˜ ê´€ê³„ (p5.js)",
    "description": "êµ¬ê¸€ì‹œíŠ¸ì˜ ëª¨ì§‘ë‹¨ì—ì„œ í‘œë³¸ì„ ì—¬ëŸ¬ ë²ˆ ì¶”ì¶œí•´ í‘œë³¸í‰ê·  ë¶„í¬ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.",
    "order": 50,
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìœ í‹¸: êµ¬ê¸€ì‹œíŠ¸ ê³µìœ  URL â†’ CSV ì£¼ì†Œë¡œ ì •ê·œí™”
def to_csv_url(url: str, sheet: str = "ì›ë³¸") -> str:
    """
    1) 'ì›¹ì— ê²Œì‹œ' CSV ì£¼ì†ŒëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©
    2) /export?format=csv ë„ ê·¸ëŒ€ë¡œ
    3) ê³µìœ  /edit ì£¼ì†ŒëŠ” gidê°€ ìˆìœ¼ë©´ export?format=csv&gid=... ë¡œ,
       ì—†ìœ¼ë©´ gviz/tq?tqx=out:csv&sheet=... (sheetëŠ” URL ì¸ì½”ë”©)
    """
    s = (url or "").strip()
    if not s:
        return s
    sl = s.lower()
    if ("output=csv" in sl) or ("/export?format=csv" in sl) or ("/gviz/tq?tqx=out:csv" in sl):
        return s

    m = re.search(r"/spreadsheets/d/([a-zA-Z0-9-_]+)", s)
    if not m:
        return s
    doc_id = m.group(1)

    parsed = urlparse(s)
    gid = None
    # #gid=... (fragment)ì—ì„œ ì¶”ì¶œ
    m_gid = re.search(r"gid=(\d+)", parsed.fragment or "")
    if m_gid:
        gid = m_gid.group(1)
    # queryì—ë„ ìˆì„ ìˆ˜ ìˆìŒ
    if not gid:
        qs = parse_qs(parsed.query or "")
        if "gid" in qs and qs["gid"]:
            gid = qs["gid"][0]

    if gid:
        return f"https://docs.google.com/spreadsheets/d/{doc_id}/export?format=csv&gid={gid}"

    sheet_enc = quote(sheet, safe="")
    return f"https://docs.google.com/spreadsheets/d/{doc_id}/gviz/tq?tqx=out:csv&sheet={sheet_enc}"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _load_population(csv_url: str) -> pd.DataFrame:
    """ì›ë³¸ CSVë¥¼ DataFrameìœ¼ë¡œ ë¡œë“œ(ìˆ«ìì—´ë§Œ ë”°ë¡œ ì„ íƒ ê°€ëŠ¥)."""
    df = pd.read_csv(csv_url)
    df = df.dropna(axis=1, how="all")
    return df

def _guess_numeric_columns(df: pd.DataFrame) -> Tuple[List[str], List[str]]:
    """
    ìˆ«ìì—´ í›„ë³´ ë°˜í™˜ + ê¸°ë³¸ ì„ íƒ ì¶”ì²œ.
    - ì²« ë²ˆì§¸ ìˆ«ìì—´ì´ 'ë°˜/í•™ê¸‰'ì²˜ëŸ¼ ë²”ì£¼ê°€ ì ì€ ì •ìˆ˜ì—´ì´ë©´ **ìë™ ì œì™¸**.
    """
    num_cols = df.select_dtypes(include=["number"]).columns.tolist()
    if not num_cols:
        return [], []

    default = num_cols.copy()
    first = num_cols[0]
    s = df[first].dropna()
    looks_class = (
        str(first).strip() in ("ë°˜", "í•™ê¸‰", "class", "Class")
        or (s.nunique() <= max(30, int(len(s) * 0.1)))  # ë²”ì£¼ê°€ ë§¤ìš° ì ìœ¼ë©´ í•™ê¸‰/ë¶„ë°˜ìœ¼ë¡œ ê°€ì •
    )
    if looks_class and len(num_cols) >= 2:
        default = num_cols[1:]  # ì²« ìˆ«ìì—´ ì œì™¸
    return num_cols, default

def _draw_samples(values: np.ndarray, n: int, m: int, seed: int) -> Tuple[List[np.ndarray], List[np.ndarray]]:
    """values(ëª¨ì§‘ë‹¨)ì—ì„œ í¬ê¸° n í‘œë³¸ì„ mê°œ ìƒì„±(ë³µì›ì¶”ì¶œ)."""
    rng = np.random.default_rng(seed)
    N = len(values)
    samples = []
    idx_lists = []
    for _ in range(m):
        idx = rng.integers(0, N, size=n)  # ë³µì›ì¶”ì¶œ
        samp = values[idx]
        samples.append(samp)
        idx_lists.append(idx)
    return samples, idx_lists

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def render():
    st.title("ëª¨í‰ê· ê³¼ í‘œë³¸í‰ê· ì˜ ê´€ê³„ (p5.js)")

    # ê¸°ë³¸ ì‹œíŠ¸(ì§ˆë¬¸ì—ì„œ ì£¼ì‹  ì£¼ì†Œ)
    default_sheet_url = "https://docs.google.com/spreadsheets/d/1APFg3_bk6NdclVvpjwzCKGXBq86u9732/edit?usp=sharing"
    with st.sidebar:
        st.subheader("ğŸ“¥ ë°ì´í„° ì†ŒìŠ¤")
        raw_url = st.text_input(
            "êµ¬ê¸€ì‹œíŠ¸ ì£¼ì†Œ",
            value=default_sheet_url,
            help="ìƒë‹¨ ê³µìœ  URLì„ ê·¸ëŒ€ë¡œ ë¶™ì—¬ë„£ì–´ë„ ë©ë‹ˆë‹¤. ì½”ë“œê°€ CSV ì£¼ì†Œë¡œ ë³€í™˜í•©ë‹ˆë‹¤."
        )
        sheet_name = st.text_input("ì‹œíŠ¸ íƒ­ ì´ë¦„", value="ì›ë³¸")
        csv_url = to_csv_url(raw_url, sheet=sheet_name)

    if not csv_url:
        st.info("ì¢Œì¸¡ì— êµ¬ê¸€ì‹œíŠ¸ ì£¼ì†Œë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        return

    # ëª¨ì§‘ë‹¨ ë¡œë“œ
    try:
        df = _load_population(csv_url)
    except Exception as e:
        st.error(f"ëª¨ì§‘ë‹¨ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return

    # ì‚¬ìš©í•  ì—´ ì„ íƒ(ìˆ«ìì—´ ì¤‘)
    num_cols, default_sel = _guess_numeric_columns(df)
    with st.sidebar:
        st.subheader("ğŸ“Š ì‚¬ìš©í•  ì—´ ì„ íƒ")
        sel_cols = st.multiselect(
            "í‚¤(ìˆ«ì) ë°ì´í„°ê°€ ë“¤ì–´ìˆëŠ” ì—´ì„ ì„ íƒí•˜ì„¸ìš”.",
            options=num_cols,
            default=default_sel
        )

        st.subheader("ğŸ² í‘œë³¸ ì„¤ì •")
        n = st.number_input("í‘œë³¸ í¬ê¸° n", 2, 1000, 30, step=1)
        m = st.number_input("í‘œë³¸ ê°œìˆ˜ m", 1, 300, 30, step=1)
        seed = st.number_input("ë‚œìˆ˜ ì‹œë“œ", 0, 10_000, 0, step=1)
        go = st.button("í‘œë³¸ ì¶”ì¶œ/ìƒˆë¡œê³ ì¹¨")

    if not sel_cols:
        st.warning("ìˆ«ì ì—´ì„ í•œ ê°œ ì´ìƒ ì„ íƒí•´ ì£¼ì„¸ìš”. (Aì—´ 'ë°˜/í•™ê¸‰'ì€ ê¸°ë³¸ ì œì™¸ë©ë‹ˆë‹¤)")
        st.dataframe(df, use_container_width=True)
        return

    # ì„ íƒí•œ ì—´ë§Œ í¼ì³ì„œ 1ì°¨ì› ë²¡í„°ë¡œ
    num_df = df[sel_cols].select_dtypes(include=["number"])
    values = num_df.to_numpy().ravel()
    values = values[~np.isnan(values)].astype(float)

    N = len(values)
    if N == 0:
        st.warning("ì„ íƒí•œ ì—´ì—ì„œ ìˆ«ì ë°ì´í„°ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.dataframe(df, use_container_width=True)
        return

    # 1) ëª¨ì§‘ë‹¨ì˜ ë¡œìš° ë°ì´í„° ë³´ê¸° (ìˆ«ìì—´ë§Œ)
    st.subheader("ğŸ“„ ëª¨ì§‘ë‹¨ ì›ë³¸ ë°ì´í„°(ì„ íƒí•œ ìˆ«ì ì—´)")
    st.caption("Aì—´ì˜ 'ë°˜/í•™ê¸‰' ë“± ë²”ì£¼í˜• ìˆ«ìì—´ì€ ê¸°ë³¸ìœ¼ë¡œ ì œì™¸í–ˆìœ¼ë©°, ì¢Œì¸¡ì—ì„œ ì§ì ‘ ì—´ì„ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    st.dataframe(num_df, use_container_width=True, height=300)
    with st.expander("ì „ì²´ ì›ë³¸ ë³´ê¸°"):
        st.dataframe(df, use_container_width=True, height=400)

    # ëª¨ì§‘ë‹¨ ê¸°ìˆ í†µê³„
    pop_mu = float(np.mean(values))
    pop_sigma = float(np.std(values, ddof=0))          # í‘œì¤€í¸ì°¨ Ïƒ
    pop_var = float(pop_sigma ** 2)                    # ë¶„ì‚° Ïƒ^2
    st.markdown(
        f"**ëª¨ì§‘ë‹¨ í¬ê¸°** N = {N:,}  \n"
        f"**ëª¨í‰ê· ** Î¼ = {pop_mu:.3f} , **ëª¨ë¶„ì‚°** ÏƒÂ² = {pop_var:.3f} (Ïƒ = {pop_sigma:.3f})"
    )

    # 2) 3) í‘œë³¸ ì¶”ì¶œ
    if go:
        st.session_state["smd_samples"], st.session_state["smd_idxlists"] = _draw_samples(values, int(n), int(m), int(seed))

    samples: List[np.ndarray] = st.session_state.get("smd_samples")
    idx_lists: List[np.ndarray] = st.session_state.get("smd_idxlists")

    if not samples:
        # ì´ˆê¸° ë Œë”ì—ì„œ ìë™ ìƒì„±
        samples, idx_lists = _draw_samples(values, int(n), int(m), int(seed))
        st.session_state["smd_samples"] = samples
        st.session_state["smd_idxlists"] = idx_lists

    # 4) ê° í‘œë³¸ í‘œ + í‘œë³¸ í†µê³„
    st.subheader("ğŸ§ª í‘œë³¸ í‘œì™€ ìš”ì•½")
    sample_rows = []
    for i, samp in enumerate(samples, start=1):
        sample_rows.append([i, len(samp), float(np.mean(samp)), float(np.std(samp, ddof=1))])
    summary_df = pd.DataFrame(sample_rows, columns=["í‘œë³¸#", "í¬ê¸°", "í‘œë³¸í‰ê· ", "í‘œë³¸í‘œì¤€í¸ì°¨"])
    st.dataframe(summary_df, use_container_width=True, height=min(300, 40 + 28 * len(samples)))

    with st.expander("ê° í‘œë³¸ì˜ ì›ì†Œ ë³´ê¸°(ìƒìœ„ 8ê°œ í‘œë³¸ë§Œ ë¯¸ë¦¬ë³´ê¸°)"):
        cap = min(8, len(samples))
        cols = st.columns(2)
        for i in range(cap):
            with cols[i % 2]:
                st.markdown(f"**í‘œë³¸ #{i+1} (n={len(samples[i])})**")
                st.dataframe(pd.DataFrame({"ê°’": samples[i]}), use_container_width=True, height=200)

    # 5) ê°€ë¡œ ìˆ˜ì§ì„ (ëª¨ì§‘ë‹¨) + ì„ íƒ í‘œë³¸ ê°•ì¡° (p5.js)
    st.subheader("ğŸ“ ëª¨ì§‘ë‹¨ ê°€ë¡œ ìˆ˜ì§ì„ ì—ì„œ í‘œë³¸ì˜ ìœ„ì¹˜(ê°•ì¡°)")
    sel_idx = st.selectbox("ê°•ì¡°í•  í‘œë³¸ ì„ íƒ", options=list(range(len(samples))), format_func=lambda i: f"í‘œë³¸ #{i+1}", index=0)

    vmin, vmax = float(np.min(values)), float(np.max(values))
    payload1 = {
        "values": values.tolist(),
        "sel_indices": [int(x) for x in idx_lists[sel_idx].tolist()],
        "vmin": vmin, "vmax": vmax,
        "title": f"ëª¨ì§‘ë‹¨({N}ëª…) ê°€ë¡œ ìˆ˜ì§ì„ ê³¼ í‘œë³¸ #{sel_idx+1} (n={len(samples[sel_idx])})"
    }
    html1 = """
<div id="popline" style="width:100%;max-width:980px;margin:0 auto;"></div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.9.0/p5.min.js"></script>
<script>
const DATA1 = """ + json.dumps(payload1) + """;
new p5((p)=>{
  let W=980,H=220, pad=40;
  p.setup=()=>{ p.createCanvas(W,H).parent("popline"); p.noLoop(); p.textFont('sans-serif'); };
  p.draw=()=>{
    p.background(255);
    const yAxis = H*0.6;
    // ì¶•(ê°€ë¡œ)
    p.stroke(50); p.strokeWeight(2);
    p.line(pad, yAxis, W-pad, yAxis);
    p.noStroke(); p.fill(0); p.textSize(12); p.textAlign(p.CENTER,p.TOP);
    p.text(DATA1.title, W/2, 8);
    p.textAlign(p.LEFT,p.TOP);  p.text(DATA1.vmin.toFixed(2), pad, yAxis+8);
    p.textAlign(p.RIGHT,p.TOP); p.text(DATA1.vmax.toFixed(2), W-pad, yAxis+8);

    const sel = new Set(DATA1.sel_indices);
    // ê²¹ì¹¨ ì™„í™”: ì•½ê°„ì˜ ìˆ˜ì§ ë‚œìˆ˜ ì§€í„°
    for (let i=0;i<DATA1.values.length;i++){
      const v = DATA1.values[i];
      const x = p.map(v, DATA1.vmin, DATA1.vmax, pad, W-pad);
      const jitter = (Math.random()-0.5)*8;
      if(sel.has(i)){ p.fill(230,49,70); p.circle(x, yAxis+jitter, 7); }
      else          { p.fill(160);       p.circle(x, yAxis+jitter, 5); }
    }
  };
});
</script>
"""
    components.html(html1, height=240)

    # 6) ì •ê·œê³¡ì„ (ëª¨ì§‘ë‹¨ vs í‘œë³¸í‰ê· ) + í‘œë³¸í‰ê·  ì  (p5.js)
    st.subheader("ğŸ“ˆ ì •ê·œê³¡ì„ : ëª¨ì§‘ë‹¨ N(Î¼, ÏƒÂ²) vs í‘œë³¸í‰ê·  N(Î¼, ÏƒÂ²/n)")
    sample_means = [float(np.mean(s)) for s in samples]
    highlight = float(np.mean(samples[sel_idx]))

    theo_sigma = pop_sigma / np.sqrt(float(n))  # í‘œë³¸í‰ê· ì˜ í‘œì¤€í¸ì°¨
    payload2 = {
        "mu_pop": pop_mu, "sd_pop": pop_sigma,
        "mu_bar": pop_mu, "sd_bar": theo_sigma,
        "sample_means": sample_means,
        "highlight": highlight,
        "title": "ì •ê·œê³¡ì„ ê³¼ í‘œë³¸í‰ê·  ìœ„ì¹˜ í‘œì‹œ"
    }
    html2 = """
<div id="gauss" style="width:100%;max-width:980px;margin:0 auto;"></div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.9.0/p5.min.js"></script>
<script>
const D2 = """ + json.dumps(payload2) + """;
new p5((p)=>{
  let W=980,H=340, left=60, right=30, top=30, bottom=60;
  function pdf(x,mu,sd){ return (1/(sd*Math.sqrt(2*Math.PI)))*Math.exp(-0.5*Math.pow((x-mu)/sd,2)); }
  p.setup=()=>{ p.createCanvas(W,H).parent("gauss"); p.noLoop(); p.textFont('sans-serif'); };
  p.draw=()=>{
    p.background(255);
    const mu=D2.mu_pop, sd=D2.sd_pop, muB=D2.mu_bar, sdB=D2.sd_bar||1e-6;

    // xë²”ìœ„ & yìµœëŒ“ê°’
    const xmin=Math.min(mu-4*sd, muB-6*sdB), xmax=Math.max(mu+4*sd, muB+6*sdB);
    let ymax=0;
    for(let i=0;i<600;i++){
      const x=xmin+(xmax-xmin)*i/599;
      ymax=Math.max(ymax, pdf(x,mu,sd), pdf(x,muB,sdB));
    }
    const X = x => p.map(x, xmin, xmax, left, W-right);
    const Y = y => p.map(y, 0,   ymax, H-bottom, top);

    // ì¶•
    p.stroke(0); p.strokeWeight(1);
    p.line(left, H-bottom, W-right, H-bottom);
    p.noStroke(); p.fill(0); p.textSize(12); p.textAlign(p.LEFT,p.TOP);
    p.text(D2.title, left, 6);

    // ëª¨ì§‘ë‹¨ ê³¡ì„ (íŒŒë‘)  N(Î¼, ÏƒÂ²)
    p.noFill(); p.stroke(35,102,235); p.strokeWeight(2); p.beginShape();
    for(let i=0;i<600;i++){ const x=xmin+(xmax-xmin)*i/599; p.vertex(X(x), Y(pdf(x,mu,sd))); } p.endShape();

    // í‘œë³¸í‰ê·  ê³¡ì„ (ì£¼í™©)  N(Î¼, ÏƒÂ²/n)
    p.noFill(); p.stroke(245,128,37); p.strokeWeight(2); p.beginShape();
    for(let i=0;i<600;i++){ const x=xmin+(xmax-xmin)*i/599; p.vertex(X(x), Y(pdf(x,muB,sdB))); } p.endShape();

    // í‘œë³¸í‰ê·  ì ë“¤(ì—°í•œ ê²€ì •)
    p.noStroke(); p.fill(0,0,0,70);
    for(const m of D2.sample_means){ p.circle(X(m), H-bottom-12, 5); }

    // ì„ íƒ í‘œë³¸ í‰ê· (ë¹¨ê°•)
    p.fill(230,49,70); p.circle(X(D2.highlight), H-bottom-12, 8);
    p.textAlign(p.CENTER,p.BOTTOM); p.fill(0);
    p.text('í˜„ì¬ í‘œë³¸ í‰ê·  '+D2.highlight.toFixed(2), X(D2.highlight), H-bottom-18);

    // ë²”ë¡€
    p.textAlign(p.LEFT,p.BOTTOM);
    p.fill(35,102,235); p.rect(left, H-28, 18, 3); p.fill(0); p.text('ëª¨ì§‘ë‹¨ N(Î¼, ÏƒÂ²)', left+26, H-34);
    p.fill(245,128,37); p.rect(left+140, H-28, 18, 3); p.fill(0); p.text('í‘œë³¸í‰ê·  N(Î¼, ÏƒÂ²/n)', left+168, H-34);
  };
});
</script>
"""
    components.html(html2, height=360)

    # 7) ëª¨ìˆ˜ vs í‘œë³¸í‰ê· (ê²½í—˜ì ) ë¹„êµ
    st.subheader("ğŸ“Š ëª¨ìˆ˜ vs í‘œë³¸í‰ê· (ê²½í—˜ì ) ë¹„êµ")
    sample_means_list = [float(np.mean(s)) for s in samples]
    mean_of_means = float(np.mean(sample_means_list))
    var_of_means = float(np.var(sample_means_list, ddof=1)) if len(sample_means_list) > 1 else float("nan")
    std_of_means = float(np.sqrt(var_of_means)) if np.isfinite(var_of_means) else float("nan")

    comp = pd.DataFrame(
        [
            ["ëª¨ì§‘ë‹¨(ì´ë¡ )", pop_mu, pop_var, pop_sigma],
            ["í‘œë³¸í‰ê· (ì´ë¡ )", pop_mu, (pop_var)/float(n), pop_sigma/np.sqrt(float(n))],
            ["í‘œë³¸í‰ê· (ê²½í—˜)", mean_of_means, var_of_means, std_of_means],
        ],
        columns=["í•­ëª©", "í‰ê· (Î¼)", "ë¶„ì‚°(ÏƒÂ²)", "í‘œì¤€í¸ì°¨(Ïƒ)"]
    )
    st.dataframe(comp, use_container_width=True, hide_index=True)

    st.caption(
        "- í‘œë³¸í‰ê· ì˜ **ì´ë¡  ë¶„ì‚°**ì€ ÏƒÂ²/n, **ì´ë¡  í‘œì¤€í¸ì°¨**ëŠ” Ïƒ/âˆšn ì…ë‹ˆë‹¤.  \n"
        "- â€˜ê²½í—˜â€™ ê°’ì€ ë°©ê¸ˆ ë§Œë“  mê°œì˜ í‘œë³¸í‰ê· ìœ¼ë¡œ ê³„ì‚°í•œ ê²°ê³¼ì…ë‹ˆë‹¤."
    )
